import streamlit as st
import pandas as pd
import requests
import google.generativeai as genai
import time
import json

# --- Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡ Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ ---
# Ø§ÛŒÙ† Ø®Ø· Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø§Ø² Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ø¯
st.set_page_config(initial_sidebar_state="expanded")

# ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù„ÛŒØ¯ API Ø§Ø² Hugging Face Secrets
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except (KeyError, FileNotFoundError):
    # Ø§Ú¯Ø± Ú©Ù„ÛŒØ¯ Ø¯Ø± Secrets Ù†Ø¨ÙˆØ¯ØŒ Ø¢Ù† Ø±Ø§ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†
    api_key = st.sidebar.text_input("Ú©Ù„ÛŒØ¯ API Ú¯ÙˆÚ¯Ù„ (Gemini)", type="password")

# Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ø¢ÛŒØ§ Ú©Ù„ÛŒØ¯ API Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡
if api_key:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-pro')
else:
    st.info("Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„ Ø´Ø¯Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡ØŒ Ú©Ù„ÛŒØ¯ API Ú¯ÙˆÚ¯Ù„ Ø®ÙˆØ¯ Ø±Ø§ (Ø¨Ø§ Ù†Ø§Ù… GOOGLE_API_KEY) Ø¯Ø± Ø¨Ø®Ø´ Secrets Ø§ÛŒÙ† Space ØªÙ†Ø¸ÛŒÙ… Ú©Ø±Ø¯Ù‡ Ùˆ ÛŒØ§ Ø¢Ù† Ø±Ø§ Ø¯Ø± Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
    st.stop()

# --- Ø¨Ù‚ÛŒÙ‡ Ú©Ø¯ Ø´Ù…Ø§ Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ---

def search_pubmed(query):
    """Ù…Ù‚Ø§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ÛŒÚ© Ù…ÙˆØ¶ÙˆØ¹ Ø±Ø§ Ø¯Ø± PubMed Ø¬Ø³ØªØ¬Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    search_url = f"{base_url}esearch.fcgi?db=pubmed&term={query}&retmax=5&sort=relevance&retmode=json"

    try:
        search_response = requests.get(search_url)
        search_data = search_response.json()

        if "esearchresult" not in search_data or not search_data["esearchresult"]["idlist"]:
            return []

        id_list = ",".join(search_data["esearchresult"]["idlist"])

        fetch_url = f"{base_url}efetch.fcgi?db=pubmed&id={id_list}&rettype=abstract&retmode=xml"
        fetch_response = requests.get(fetch_url)

        import xml.etree.ElementTree as ET

        articles = []
        root = ET.fromstring(fetch_response.content)
        for article in root.findall('.//PubmedArticle'):
            title_element = article.find('.//ArticleTitle')
            abstract_element = article.find('.//AbstractText')

            title = title_element.text if title_element is not None else "No Title"
            abstract = abstract_element.text if abstract_element is not None else "No Abstract"

            articles.append({'title': title, 'abstract': abstract})

        return articles

    except requests.exceptions.RequestException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ PubMed: {e}")
        return []
    except ET.ParseError as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® XML Ø§Ø² PubMed: {e}")
        return []

st.title("ğŸ”¬ Ø¯Ø³ØªÛŒØ§Ø± Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯")
topic = st.text_input("Ù…ÙˆØ¶ÙˆØ¹ ØªØ­Ù‚ÛŒÙ‚ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")

if topic:
    st.write(f"Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ: {topic}")
    
    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± PubMed..."):
        articles = search_pubmed(topic)

    if articles:
        st.success(f"ØªØ¹Ø¯Ø§Ø¯ {len(articles)} Ù…Ù‚Ø§Ù„Ù‡ ÛŒØ§ÙØª Ø´Ø¯.")
        st.session_state.articles = articles

        for i, article in enumerate(articles):
            with st.expander(f"Ù…Ù‚Ø§Ù„Ù‡ {i+1}: {article['title']}"):
                st.markdown(article['abstract'])

        # Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
        if st.button("ÛŒØ§ÙØªÙ† Ú¯Ù¾â€ŒÙ‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ"):
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„..."):
                abstracts = [article['abstract'] for article in articles if article['abstract'] != "No Abstract"]

                if not abstracts:
                    st.warning("Ù‡ÛŒÚ† Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    st.stop()

                prompt = f"Based on the following abstracts on the topic '{topic}', identify and summarize potential research gaps. Please present the gaps as a bulleted list:\n\n" + "\n\n".join(abstracts)
                response = model.generate_content(prompt)
                st.markdown("---")
                st.subheader("Ú¯Ù¾â€ŒÙ‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡:")
                st.markdown(response.text)
    else:
        st.warning("Ù‡ÛŒÚ† Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")