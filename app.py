import streamlit as st
import pandas as pd
import requests
import google.generativeai as genai
import time
import json

# --- Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡ Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ ---
# Ø§ÛŒÙ† Ø®Ø· Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø§Ø² Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ø¯
st.set_page_config(initial_sidebar_state="expanded")

# ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù„ÛŒØ¯ API Ø§Ø² Hugging Face Secrets
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except (KeyError, FileNotFoundError):
    # Ø§Ú¯Ø± Ú©Ù„ÛŒØ¯ Ø¯Ø± Secrets Ù†Ø¨ÙˆØ¯ØŒ Ø¢Ù† Ø±Ø§ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†
    api_key = st.sidebar.text_input("Ú©Ù„ÛŒØ¯ API Ú¯ÙˆÚ¯Ù„ (Gemini)", type="password")

# Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ø¢ÛŒØ§ Ú©Ù„ÛŒØ¯ API Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡
if api_key:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-pro')
else:
    st.info("Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„ Ø´Ø¯Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡ØŒ Ú©Ù„ÛŒØ¯ API Ú¯ÙˆÚ¯Ù„ Ø®ÙˆØ¯ Ø±Ø§ (Ø¨Ø§ Ù†Ø§Ù… GOOGLE_API_KEY) Ø¯Ø± Ø¨Ø®Ø´ Secrets Ø§ÛŒÙ† Space ØªÙ†Ø¸ÛŒÙ… Ú©Ø±Ø¯Ù‡ Ùˆ ÛŒØ§ Ø¢Ù† Ø±Ø§ Ø¯Ø± Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
    st.stop()

# --- Ø¨Ù‚ÛŒÙ‡ Ú©Ø¯ Ø´Ù…Ø§ Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ---

def search_pubmed(query, max_results=10):
    """Ù…Ù‚Ø§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ÛŒÚ© Ù…ÙˆØ¶ÙˆØ¹ Ø±Ø§ Ø¯Ø± PubMed Ø¬Ø³ØªØ¬Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    search_url = f"{base_url}esearch.fcgi?db=pubmed&term={query}&retmax={max_results}&sort=relevance&retmode=json"

    try:
        search_response = requests.get(search_url)
        search_data = search_response.json()

        if "esearchresult" not in search_data or not search_data["esearchresult"]["idlist"]:
            return []

        id_list = ",".join(search_data["esearchresult"]["idlist"])

        fetch_url = f"{base_url}efetch.fcgi?db=pubmed&id={id_list}&rettype=abstract&retmode=xml"
        fetch_response = requests.get(fetch_url)

        import xml.etree.ElementTree as ET

        articles = []
        root = ET.fromstring(fetch_response.content)
        for article_xml in root.findall('.//PubmedArticle'):
            # --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù…Ù„ Ù…Ù‚Ø§Ù„Ù‡ ---
            pmid_element = article_xml.find('.//PMID')
            pmid = pmid_element.text if pmid_element is not None else ""

            title_element = article_xml.find('.//ArticleTitle')
            title = title_element.text if title_element is not None else "No Title Available"

            abstract_element = article_xml.find('.//AbstractText')
            abstract = abstract_element.text if abstract_element is not None else "No Abstract Available"

            author_elements = article_xml.findall('.//AuthorList/Author')
            authors = []
            for author in author_elements:
                last_name = author.find('LastName')
                fore_name = author.find('ForeName')
                if last_name is not None and fore_name is not None:
                    authors.append(f"{last_name.text}, {fore_name.text}")
            authors_str = " and ".join(authors)

            journal_element = article_xml.find('.//Journal/Title')
            journal = journal_element.text if journal_element is not None else "N/A"

            year_element = article_xml.find('.//PubDate/Year')
            year = year_element.text if year_element is not None else "N/A"

            articles.append({
                'pmid': pmid,
                'title': title,
                'abstract': abstract,
                'authors': authors_str,
                'journal': journal,
                'year': year
            })

        return articles

    except requests.exceptions.RequestException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ PubMed: {e}")
        return []
    except ET.ParseError as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® XML Ø§Ø² PubMed: {e}")
        return []

st.title("ğŸ”¬ Ø¯Ø³ØªÛŒØ§Ø± Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯")

# Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ø³Ø§ÛŒØ¯Ø¨Ø§Ø±
with st.sidebar:
    st.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø³ØªØ¬Ùˆ")
    topic = st.text_input("Ù…ÙˆØ¶ÙˆØ¹ ØªØ­Ù‚ÛŒÙ‚ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:", placeholder="Ù…Ø«Ù„Ø§Ù‹: New treatments for Alzheimer's")
    num_articles = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª:", min_value=5, max_value=100, value=10, step=5)
    output_language = st.selectbox("Ø²Ø¨Ø§Ù† Ø®Ø±ÙˆØ¬ÛŒ ØªØ­Ù„ÛŒÙ„:", ("ÙØ§Ø±Ø³ÛŒ", "English", "Deutsch", "FranÃ§ais", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"))

if topic:
    st.write(f"Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ {num_articles} Ù…Ù‚Ø§Ù„Ù‡ Ø¯Ø± Ù…ÙˆØ±Ø¯: {topic}")
    
    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± PubMed..."):
        articles = search_pubmed(topic, max_results=num_articles)

    if articles:
        st.success(f"ØªØ¹Ø¯Ø§Ø¯ {len(articles)} Ù…Ù‚Ø§Ù„Ù‡ ÛŒØ§ÙØª Ø´Ø¯.")
        st.session_state.articles = articles

        # --- Ø¨Ø®Ø´ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù†Ø§Ø¨Ø¹ ---
        def generate_bibtex(articles_list):
            bib_entries = []
            for article in articles_list:
                # Sanitize characters for BibTeX
                title = article['title'].replace('{', '').replace('}', '')
                authors = article['authors'].replace('{', '').replace('}', '')

                bib_entry = (
                    f"@article{{{article['pmid']},\n"
                    f"  author    = {{{authors}}},\n"
                    f"  title     = {{{title}}},\n"
                    f"  journal   = {{{article['journal']}}},\n"
                    f"  year      = {{{article['year']}}},\n"
                    f"  pmid      = {{{article['pmid']}}}\n"
                    f"}}"
                )
                bib_entries.append(bib_entry)
            return "\n\n".join(bib_entries)

        bibtex_str = generate_bibtex(articles)
        st.download_button(
            label="Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ BibTeX",
            data=bibtex_str,
            file_name=f"{topic.replace(' ', '_')}_references.bib",
            mime="application/x-bibtex",
        )
        # --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù†Ø§Ø¨Ø¹ ---

        for i, article in enumerate(articles):
            with st.expander(f"Ù…Ù‚Ø§Ù„Ù‡ {i+1}: {article['title']}"):
                st.markdown(f"**Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†:** {article['authors']}")
                st.markdown(f"**Ú˜ÙˆØ±Ù†Ø§Ù„:** {article['journal']} ({article['year']})")
                st.markdown(f"**Ú†Ú©ÛŒØ¯Ù‡:**\n{article['abstract']}")

        st.markdown("---")
        st.subheader("Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡")

        # Ø§ÛŒØ¬Ø§Ø¯ Ú†Ù‡Ø§Ø± Ø³ØªÙˆÙ† Ø¨Ø±Ø§ÛŒ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            if st.button("ÛŒØ§ÙØªÙ† Ú¯Ù¾â€ŒÙ‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ"):
                with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ú¯Ù¾â€ŒÙ‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ..."):
                    abstracts = [article['abstract'] for article in articles if article['abstract'] != "No Abstract"]
                    if not abstracts:
                        st.warning("Ù‡ÛŒÚ† Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    else:
                        prompt = f"Based on the following abstracts on the topic '{topic}', identify and summarize potential research gaps. Please present the gaps as a bulleted list.\n\n**Abstracts:**\n" + "\n\n".join(abstracts) + f"\n\n**IMPORTANT: The final output must be in {output_language}.**"
                        response = model.generate_content(prompt)
                        st.subheader(f"Ú¯Ù¾â€ŒÙ‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡ (Ø¨Ù‡ Ø²Ø¨Ø§Ù† {output_language}):")
                        st.markdown(response.text)

        with col2:
            if st.button("Ù†ÙˆØ´ØªÙ† Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ Ù…Ø±ÙˆØ± Ø§Ø¯Ø¨ÛŒØ§Øª"):
                with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù†ÙˆØ´ØªÙ† Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ Ù…Ø±ÙˆØ± Ø§Ø¯Ø¨ÛŒØ§Øª..."):
                    abstracts = [article['abstract'] for article in articles if article['abstract'] != "No Abstract"]
                    if not abstracts:
                        st.warning("Ù‡ÛŒÚ† Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†ÙˆØ´ØªÙ† Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    else:
                        prompt = f"Write a literature review draft based on the following abstracts on the topic '{topic}'. The draft should be well-structured, coherent, and synthesize the key findings from the articles. It should include an introduction, thematic sections, and a conclusion identifying the main research gaps.\n\n**Abstracts:**\n" + "\n\n".join(abstracts) + f"\n\n**IMPORTANT: The final output must be in {output_language}.**"
                        response = model.generate_content(prompt)
                        st.subheader(f"Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ Ù…Ø±ÙˆØ± Ø§Ø¯Ø¨ÛŒØ§Øª (Ø¨Ù‡ Ø²Ø¨Ø§Ù† {output_language}):")
                        st.markdown(response.text)

        with col3:
            # Ø¨Ø®Ø´ Ø³Ø§Ø®Øª Ù¾Ø±ÙˆÙ¾ÙˆØ²Ø§Ù„
            with st.expander("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø§Ø®Øª Ù¾Ø±ÙˆÙ¾ÙˆØ²Ø§Ù„"):
                default_proposal_format = """
1. **Ø¹Ù†ÙˆØ§Ù† ØªØ­Ù‚ÛŒÙ‚ (Title)**:
2. **Ø¨ÛŒØ§Ù† Ù…Ø³Ø¦Ù„Ù‡ (Problem Statement)**:
3. **Ø§Ù‡Ù…ÛŒØª Ùˆ Ø¶Ø±ÙˆØ±Øª ØªØ­Ù‚ÛŒÙ‚ (Significance of the Study)**:
4. **Ø§Ù‡Ø¯Ø§Ù ØªØ­Ù‚ÛŒÙ‚ (Research Objectives)**:
   - Ù‡Ø¯Ù Ø§ØµÙ„ÛŒ
   - Ø§Ù‡Ø¯Ø§Ù ÙØ±Ø¹ÛŒ
5. **Ø³ÙˆØ§Ù„Ø§Øª ØªØ­Ù‚ÛŒÙ‚ (Research Questions)**:
6. **Ø±ÙˆØ´ ØªØ­Ù‚ÛŒÙ‚ (Methodology)**:
7. **Ø¬Ø§Ù…Ø¹Ù‡ Ùˆ Ù†Ù…ÙˆÙ†Ù‡ Ø¢Ù…Ø§Ø±ÛŒ (Population and Sample)**:
8. **Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú¯Ø±Ø¯Ø¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Data Collection Tools)**:
9. **Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚ (Limitations)**:
"""
                proposal_format = st.text_area("ÙØ±Ù…Øª Ù¾Ø±ÙˆÙ¾ÙˆØ²Ø§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ ÛŒØ§ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯:", value=default_proposal_format, height=300)

            if st.button("Ø³Ø§Ø®Øª Ù¾Ø±ÙˆÙ¾ÙˆØ²Ø§Ù„"):
                with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Ù¾Ø±ÙˆÙ¾ÙˆØ²Ø§Ù„..."):
                    abstracts = [article['abstract'] for article in articles if article['abstract'] != "No Abstract"]
                    if not abstracts:
                        st.warning("Ù‡ÛŒÚ† Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ù¾Ø±ÙˆÙ¾ÙˆØ²Ø§Ù„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    else:
                        prompt = f"""
As an expert academic assistant, generate a comprehensive research proposal on the topic '{topic}'.
Use the information from the following article abstracts to fill out each section of the proposal.
The proposal must strictly follow the provided format.

**Article Abstracts:**
{"\n\n".join(abstracts)}

**Proposal Format to Follow:**
{proposal_format}

**IMPORTANT: The final output must be in {output_language}. If the proposal format is in a different language, translate the generated content to the language of the format.**
"""
                        response = model.generate_content(prompt)
                        st.subheader(f"Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ Ù¾Ø±ÙˆÙ¾ÙˆØ²Ø§Ù„ ØªØ­Ù‚ÛŒÙ‚ (Ø¨Ù‡ Ø²Ø¨Ø§Ù† {output_language}):")
                        st.markdown(response.text)

        with col4:
            if st.button("ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¶ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"):
                with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¶ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡..."):
                    abstracts = [f"Title: {a['title']}\nAbstract: {a['abstract']}" for a in articles if a['abstract'] != "No Abstract"]
                    if not abstracts:
                        st.warning("Ù‡ÛŒÚ† Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    else:
                        prompt = f"""
As a senior researcher, perform an in-depth thematic analysis of the following article abstracts on the topic '{topic}'.
Based on your analysis, provide a comprehensive report that includes:
1.  **Main Research Themes**: Identify and describe the dominant themes or sub-topics discussed across the articles.
2.  **Common Methodologies**: Summarize the most frequently used research methods and approaches.
3.  **Key Debates and Discussions**: Highlight any conflicting findings, ongoing debates, or key discussions in the field.
4.  **Prominent Authors/Groups**: If possible, identify any authors or research groups that appear frequently.

**Article Abstracts:**
{"\n\n---\n\n".join(abstracts)}

**IMPORTANT: The final output must be in {output_language}.**
"""
                        response = model.generate_content(prompt)
                        st.subheader(f"ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¶ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Ø¨Ù‡ Ø²Ø¨Ø§Ù† {output_language}):")
                        st.markdown(response.text)
    else:
        st.warning("Ù‡ÛŒÚ† Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")